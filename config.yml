# =============================================================================
# LLM Pruning with TD3 - Configuration
# =============================================================================

random_state: 42

# -----------------------------------------------------------------------------
# Grouping (clustering neurons) - now simplified to importance-based pruning
# -----------------------------------------------------------------------------
grouping:
  n_samples: 100
  percentile_threshold: 70
  layers_grouped: 2
  random_state: 42
  
  dim_reduction:
    name: UMAP
    n_components: 40
  
  clustering:
    name: KMeansConstrained
    k: 16
    group_size_deviation: 0.4

# -----------------------------------------------------------------------------
# Neuron Importance (for simplified pruning)
# -----------------------------------------------------------------------------
importance:
  path: neuron_importance_up_proj.json

# -----------------------------------------------------------------------------
# Model (LLM to prune)
# -----------------------------------------------------------------------------
model:
  name: meta-llama/Meta-Llama-3.1-8B-Instruct
  dtype: bfloat16

# -----------------------------------------------------------------------------
# Encoder (for state embedding)
# -----------------------------------------------------------------------------
encoder:
  name: answerdotai/ModernBERT-base
  embed_dim: 768

# -----------------------------------------------------------------------------
# Data
# -----------------------------------------------------------------------------
data:
  dataset: wikitext          # wikitext or mmlu
  train_samples: null       # max samples for training (null for all)
  mmlu_subjects: null    # list of subjects or null for all (only for mmlu)

# -----------------------------------------------------------------------------
# Environment
# -----------------------------------------------------------------------------
environment:
  max_seq_len: 2048          # max tokens for perplexity calculation
  quality_weight: 0.5        # weight for quality (ppl/acc) vs sparsity reward
  baseline_perplexity: 9.57  # optional: if set, use this constant baseline for speed

# -----------------------------------------------------------------------------
# TD3 Hyperparameters
# -----------------------------------------------------------------------------
td3:
  learning_rate: 1.0e-4        # Slightly higher than SAC as it's more stable
  buffer_size: 10000           # Matched to your 5k step limit
  batch_size: 256              # Better for continuous control
  tau: 0.005                   # Target network update rate
  gamma: 0.0                   # Still 0 for Contextual Bandit
  train_freq: 1
  gradient_steps: 5            # High to extract more info per LLM eval
  
  # TD3 Specifics
  policy_delay: 2              # Update actor every 2 critic updates (standard)
  target_policy_noise: 0.2     # Noise added to target policy (smoothing)
  target_noise_clip: 0.5       # Range to clip target noise
  
  # Policy network architecture
  pi_layers: [512, 256]        # Classic TD3 architecture
  qf_layers: [512, 256]
  action_bias: 0.05            # initial bias for action mean (fraction to prune per layer)

# -----------------------------------------------------------------------------
# Training
# -----------------------------------------------------------------------------
training:
  total_timesteps: 15000
  log_interval: 50
  save_path: checkpoints/td3_pruning_agent
  device: cuda             
  verbose: 1

# -----------------------------------------------------------------------------
# Evaluation
# -----------------------------------------------------------------------------
evaluation:
  deterministic: true        # use deterministic policy (no exploration)





